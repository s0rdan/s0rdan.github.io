---
layout: post
title: AGI Notes
---


### s0rdan's Notes on *Artificial General Intelligence via the CogPrime Architecture* (B. Goertzel et al.) 


####1. Introduction

The cognitive synergy ensuing from integrating multiple symbolic and sub-symbolic learning and memory components in an appropriate cognitive architecture and environment can yield robust intelligence at the human level and eventually beyond.
 A mind uses **perception** and **memory** to make **predictions** about which **actions** will help it achieve its **goals**.


####2. What Is Human-Like General Intelligence?

The problem of AGI is really a problem of coping with inadequate compute resources (computing efficiency), just as the problem of natural intelligence is really a problem of coping with inadequate energetic resources. Virtual vs (robotically) Embodied. Lack of a (really) rigorous and thorough general technical theory of GI. GI is the capacity of a system to choose actions maximizing its goal-achievement, based on its perceptions and memories, and making a reasonably efficient use of its computational resources.

> Look into the [AIXI<sup>tl</sup> algorithm](http://www.hutter1.net/ai/aixigentle.pdf) (Marcus Hutter), Baars' [Global Workspace theory](http://ccrg.cs.memphis.edu/assets/papers/2004/Baars%20PBR%202004%20GW%20Theory.pdf)

Elements of human intelligence: Perception, Motor Control, Memory, Knowledge Representation, Language, Consciousness, Thinking, Social Intelligence.
Building an AGI with similar qualities as a 3 years old human and putting it in a preschool environment. "Build me something out of blocks, that you haven't built before, and tell me what it is."

Ultimately, the purpose of cognitive synergy in an AGI system is to enable the various AI algorithms and structures composing the system to work together effectively enough to give rise to the right *system-wide emergent structures* characterising real-world general intelligence.

Four primary challenges:

1. Overall Cognitive Architecture
2. Appropriate AI Algorithms and data structures
3. Coordinated, synergetic intelligent behaviour
4. An environment providing sufficiently rich stimuli and interactions


####3. A Patternist Philosophy of mind

The mind of a system is the fuzzy set of different simplifying representations (patterns) of that system, which may be adopted. Intelligence is the ability of achieving complex goals in a complex environment. *Self-organization*, *goal-oriented behaviour* control high level cognitive dynamics: evolution, autopoiesis (interdependence), association, differential attention allocation, pattern creation. These give rise to large scale emergent structures: (1) hierarchical network, (2) heterarchical, dual (1+2), self structure. Multi-memory (types) architecture: declarative, procedural, sensory, episodic, attentional, intentional.

> Look at Goertzel's "[*The Hidden Pattern*](http://www.goertzel.org/HiddenPattern_march_4_06.pdf)"

Cross mechanism interaction between different knowledge types cause knowledge creation mechanism to perform more effectively (cognitive synergy), palliating combinatorial explosion. 